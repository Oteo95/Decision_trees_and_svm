{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"datamecum_logo.png\" align=\"right\" style=\"float\" width=\"400\">\n",
    "<font color=\"#CA3532\"><h1 align=\"left\">Programa técnico intensivo en data science. Datamecum.</h1></font>\n",
    "<font color=\"#6E6E6E\"><h2 align=\"left\">Decision Trees</h2></font> \n",
    "<font color=\"#6E6E6E\"><h2 align=\"left\">Construcción del árbol</h2></font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de la entropía\n",
    "\n",
    "Podemos generalizarla para una variable aleatoria discreta ``X`` de ``n`` resultados como:\n",
    "\n",
    "$$\n",
    "    H(X) = - \\sum_{i=1}^n p(x_{i}) * log_{2}(p(x_{i}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def H(values):\n",
    "    valor = 0\n",
    "\n",
    "    for value in values:\n",
    "        if (value > 0):\n",
    "            valor = valor + value * log(value, 2)\n",
    "    \n",
    "    return - valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arboles de Decisión: ID3\n",
    "\n",
    "- Algoritmo de Tipo Greedy\n",
    "    - En cada paso realiza el mejor split posible en dos con un cierto criterio:\n",
    "        - Seleccionar el atributo que nos da mayor **Ganancia de Información**.\n",
    "    - Proceso se repite recursivamente hasta construir el árbol final.\n",
    "\n",
    "La **Ganancia de informacion** se ira calculando en cada paso, calculando la diferencia entre la entropia antes de realizar un split y despues de realizar el mismo por un cierto feature. Esta se puede interpretar como que al realizar un determinado split, se reduce la incertidumbre de la prediccion en ese sub-arbol dado un cierto valor.\n",
    "\n",
    "El hecho de que el algoritmo sea greedy se manifiesta en que nos quedaremos con aquel feature que nos da **mayor ganancia de informacion**.\n",
    "\n",
    "Veremos un ejemplo para poder comprender el concepto\n",
    "\n",
    "### Set de datos\n",
    "\n",
    "| candidato | presencia | estudios | experiencia | contratado  |\n",
    "|-----------|-----------|----------|-------------|-------------|\n",
    "| 1\t\t\t| buena\t\t| univ\t   | alta   \t | *si*\t\t   |\n",
    "| 2\t\t\t| mala\t\t| univ\t   | media  \t | **no**\t   |\n",
    "| 3\t\t\t| buena\t\t| sec\t   | alta   \t | *si*\t\t   |\n",
    "| 4\t\t\t| mala\t\t| univ\t   | baja   \t | **no**\t   |\n",
    "| 5\t\t\t| buena\t\t| sec\t   | media\t \t | *si*\t\t   |\n",
    "| 6\t\t\t| buena\t\t| univ\t   | media  \t | *si*\t\t   |\n",
    "| 7\t\t\t| reg\t\t| pri\t   | baja   \t | **no**\t   |\n",
    "| 8\t\t\t| reg\t\t| univ\t   | media  \t | *si*\t\t   |\n",
    "\n",
    "### ¿Qué queremos predecir?\n",
    "\n",
    "Queremos predecir si la persona **será o no sera contratada** y siempre sera la base que utilizaremos para calcular la entropia.\n",
    "\n",
    "### Features a considerar\n",
    "\n",
    "- presencia\n",
    "- estudios\n",
    "- experiencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer Nivel\n",
    "\n",
    "Calculamos la entropia del set de datos donde tenemos:\n",
    "\n",
    "- 8 candidatos\n",
    "    - **5 FUERON contratados**\n",
    "    - **3 NO FUERON contratados**\n",
    "    \n",
    "Calculamos entonces la entropía del set de datos (antes de realizar un split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544340029249649"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H([5/8, 3/8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_before = H([5/8, 3/8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si consideramos como candidato para el split nuestro primer atributo **presencia** podemos ver que cuenta con los siguientes valores:\n",
    "\n",
    "- buena\n",
    "- mala\n",
    "- regular\n",
    "\n",
    "y a su vez podemos considerar parcialmente cada uno de los casos que se corresponden con lo que queremos *predecir*.\n",
    "\n",
    "|presencia | contratado  | no contratado |\n",
    "|----------|-------------|---------------|\n",
    "| buena\t   | 4           |0|   \n",
    "| mala\t   | 0           |2| \n",
    "| reg\t   | 1           |1|\n",
    "\n",
    "Para poder calcular la **ganancia de informacion** tenemos que obtener la **entropia para el feature presencia**. Para ello calculamos la entropia para cada valor posible del feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#H(presencia=buena)\n",
    "H([4/4,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#H(presencia=mala)\n",
    "H([0,2/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#H(presencia=reg)\n",
    "H([1/2,1/2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y por ultimo podemos expresar la **entropia del feature presencia** como **el promedio ponderado de la entropia de cada valor posible por la probabilidad de que el atributo tome dicho valor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H(presencia)\n",
    "4/8 * H([4/4,0]) + 2/8 * H([0,2/2]) + 2/8 * H([1/2,1/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_after_presence = 4/8 * H([4/4,0]) + 2/8 * H([0,2/2]) + 2/8 * H([1/2,1/2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo el calculo de la **Ganancia de Informacion** lo realizamos como la diferencia entre la entropia del set de datos (al inicio) y la entropia del atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7044340029249649"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IG(presencia)\n",
    "h_before - h_after_presence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma podemos realizar el mismo calculo para los otros atributos. Por ejemplo la ganancia de la información de estudios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34758988139079705"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_before - (1/8 * H([0,1/1]) + 2/8 * H([2/2,0]) + 5/8 * H([3/5,2/5]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien podemos repetir el proceso para la ganancia de la información de la experiencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5487949406953985"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_before - (2/8 * H([2/2,0]) + 4/8 * H([1/4, 3/4]) + 2/8 * H([0, 2/2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **feature/atributo con mayor ganancia de informacion** es *presencia* por lo que sera nuestra raiz del arbol de decision.\n",
    "\n",
    "Podemos ver la siguiente representacion del mismo. Es importante notar que nuestro arbol de decision ya clasifica correctamente los casos de presencia buena y mala (no quedando casos sin clasificar)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "         presencia\n",
    "         [5si,3no]              \n",
    "\n",
    "    /        |       \\                 \n",
    "  =buena   =mala     =reg\n",
    " -------  --------  -------\n",
    "[4si,0no] [0si,2no] [1si,1no]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo Nivel\n",
    "\n",
    "Por ultimo nos quedan los casos de regular, en los cuales tenemos un contratado y un no contratado y dos features a evaluar: estudios y experiencia. \n",
    "\n",
    "Para poder hacerlo debemos aplicar nuevamente el algoritmo recursivamente considerando el nuevo set de datos con los elementos que quedan en ese sub-set de datos del nodo (los dos dentro cuya presencia fue regular).\n",
    "\n",
    "Tenemos que calcular la la Ganancia de Informacion, pero en este caso podemos hacer esto sin cuentas porque observamos que en los dos casos en los cuales la presencia es regular podemos usar tanto los estudios como la experiencia para hacer el split, por lo que un posible ejemplo podria ser el siguiente:\n",
    "\n",
    "```\n",
    "         presencia\n",
    "         [5si,3no]               \n",
    "                                 \n",
    "    /        |       \\                 \n",
    "  =buena   =mala     estudios\n",
    " -------  --------    -------\n",
    "[4si,0no] [0si,2no]  [1si,1no]\n",
    "                    \n",
    "                     /        \\\n",
    "                   =pri      =univ\n",
    "                 [0si,1no]  [1si,0no]\n",
    "```\n",
    "\n",
    "\n",
    "Ejercicios: Comprobar si el la seleccion de la variable en el segundo nivel está bien realizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
